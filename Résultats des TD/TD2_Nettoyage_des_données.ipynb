{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TD : Nettoyage des Données Textuelles en Python pour le NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectifs du TD :\n",
    "\n",
    "— Comprendre l’importance du nettoyage des données textuelles pour le NLP.\n",
    "\n",
    "— Manipuler des bibliothèques Python pour normaliser et nettoyer des textes.\n",
    "\n",
    "— Préparer les données collectées pour des applications de traitement automatique du langage.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Prérequis :\n",
    "\n",
    "— Données textuelles collectées via une API ou du web scraping (par exemple, à\n",
    "partir du premier TD).\n",
    "\n",
    "— Python 3.7+\n",
    "\n",
    "— Bibliothèques nécessaires : NLTK, Pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plan du TD :\n",
    "\n",
    "1. Introduction au nettoyage des données\n",
    "\n",
    "2. Nettoyage des textes : suppression des caractères inutiles\n",
    "\n",
    "3. Tokenisation et normalisation\n",
    "\n",
    "4. Sauvegarde des données nettoyées\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1 Introduction au nettoyage des données\n",
    "\n",
    "Les données brutes collectées contiennent souvent du bruit (caractères spéciaux, liens, mentions inutiles) qui doit être nettoyé avant leur utilisation dans des modèles NLP.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Réponses aux questions: \n",
    "\n",
    "### 1. Pourquoi est-il important de nettoyer les données textuelles pour le NLP ?\n",
    "\n",
    "   Le nettoyage de texte est utile, car il permet d'uniformiser les tokens similaires, réduisant ainsi la taille du vocabulaire\n",
    "\n",
    "### 2. Quels sont les principaux types de bruit dans les textes collectés ?\n",
    "\n",
    "  Les principaux types de bruit dans les textes collectés sont :\n",
    "\n",
    " -Données inutiles ou hors sujet : Textes publicitaires, menus de navigation, ou informations redondantes (ex. : copyright, liens).\n",
    "\n",
    "-Caractères spéciaux et ponctuation excessive : Symboles non pertinents (#, *, &, etc.) ou ponctuation répétée.\n",
    "\n",
    "- Balises HTML ou contenu non nettoyé : Balises ou scripts restants après l'extraction (ex. : <div>, <script>).\n",
    "\n",
    "- Erreurs typographiques et grammaticales : Fautes de frappe ou mauvaise syntaxe, surtout dans les contributions générées par des utilisateurs.\n",
    "\n",
    "- Langue mixte ou ambiguïté linguistique : Mélange de langues ou utilisation de mots ayant plusieurs significations\n",
    "    \n",
    "-  Contenu dupliqué : Répétitions fréquentes d'informations similaires ou identiques.\n",
    "\n",
    "- Données manquantes ou incohérentes : Lignes vides, phrases incomplètes, ou incohérence dans le formatage.\n",
    "   \n",
    "-  Ces bruits nécessitent un nettoyage et une prétraitement pour garantir la qualité des données avant toute analyse NLP.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - Nettoyage des textes : suppression des caractères inutiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Étapes à suivre :\n",
    "\n",
    "— Identifier et supprimer les caractères spéciaux et hyperliens.\n",
    "\n",
    "— Convertir les textes en minuscules.\n",
    "\n",
    "— Supprimer les espaces inutiles et normaliser le format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemple de comparaison avant/après nettoyage :\n",
      "Texte brut : The Role of Telomerase in Breast Cancer's Response to Therapy - PubMed\n",
      "Texte nettoyé : the role of telomerase in breast cancers response to therapy pubmed\n",
      "\n",
      "Texte brut : This site needs JavaScript to work properly. Please enable it to take advantage of the complete set of features!\n",
      "Texte nettoyé : this site needs javascript to work properly please enable it to take advantage of the complete set of features\n",
      "\n",
      "Texte brut : Clipboard, Search History, and several other advanced features are temporarily unavailable.\n",
      "Texte nettoyé : clipboard search history and several other advanced features are temporarily unavailable\n",
      "\n",
      "Texte brut : Skip to main page content\n",
      "Texte nettoyé : skip to main page content\n",
      "\n",
      "Texte brut : An official website of the United States government\n",
      "Texte nettoyé : an official website of the united states government\n",
      "\n",
      "Les textes nettoyés ont été sauvegardés dans 'contenu_textuel_nettoye.csv'.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Charger le fichier CSV\n",
    "input_file = 'contenu_textuel_extrait.csv'  \n",
    "output_file = 'contenu_textuel_nettoye.csv' \n",
    "\n",
    "# Chargement des données\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# Fonction de nettoyage des textes\n",
    "def clean_text(text):\n",
    "    if isinstance(text, str):\n",
    "        # Suppression des hyperliens\n",
    "        text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text)  # Supprimer les URLs\n",
    "        # Suppression des caractères spéciaux\n",
    "        text = re.sub(r'[^\\w\\s]', '', text)  # Garder uniquement les lettres, chiffres, et espaces\n",
    "        # Convertion  en minuscules\n",
    "        text = text.lower()\n",
    "        # Suppression des espaces inutiles\n",
    "        text = text.strip() # Supprimer les espaces au début et à la fin\n",
    "        text = re.sub(r'\\s+', ' ', text)  # Remplacement des espaces multiples par un seul\n",
    "    return text\n",
    "\n",
    "# Appliquer le nettoyage\n",
    "df['contenu_textuel_nettoye'] = df['contenu_textuel_extrait'].apply(clean_text)\n",
    "\n",
    "# Comparer quelques exemples avant et après nettoyage\n",
    "print(\"Exemple de comparaison avant/après nettoyage :\")\n",
    "for _, row in df.head(5).iterrows():\n",
    "    print(f\"Texte brut : {row['contenu_textuel_extrait']}\")\n",
    "    print(f\"Texte nettoyé : {row['contenu_textuel_nettoye']}\\n\")\n",
    "\n",
    "# Sauvegarder les résultats dans un fichier CSV dans le répertoire courant\n",
    "df.to_csv(output_file, index=False, encoding='utf-8')\n",
    "print(f\"Les textes nettoyés ont été sauvegardés dans '{output_file}'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse des résultats :\n",
    "\n",
    "### -  Comparez les textes bruts aux textes nettoyés.\n",
    "Les textes bruts contiennent des éléments non pertinents comme des caractères spéciaux, des références à des plateformes (PubMed, JavaScript) et des hyperliens inutilisables. Après nettoyage, les majuscules sont converties en minuscules, les caractères spéciaux et hyperliens supprimés, et les espaces superflus éliminés, offrant un format normalisé.\n",
    "\n",
    "\n",
    "### - Identifiez les limites potentielles du nettoyage effectué.\n",
    "Le nettoyage peut entraîner une perte d'informations utiles, comme les apostrophes ou des noms significatifs tels que \"PubMed\". Les mots communs inutiles (stopwords) restent présents, et aucune correction grammaticale n'est effectuée. Les textes génériques ou hors sujet ne sont pas filtrés, et une suppression excessive d'éléments peut rendre les phrases incohérentes ou incomplètes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokénisatiion et normalisation des textes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Étapes à suivre :\n",
    "\n",
    "— Divisez les textes en unités lexicales (tokens) à l’aide d’une bibliothèque comme NLTK.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting nltk\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.5 MB 1.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting click\n",
      "  Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "\u001b[K     |████████████████████████████████| 97 kB 23.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting joblib\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "\u001b[K     |████████████████████████████████| 301 kB 43.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting regex>=2021.8.3\n",
      "  Downloading regex-2024.11.6-cp39-cp39-macosx_11_0_arm64.whl (284 kB)\n",
      "\u001b[K     |████████████████████████████████| 284 kB 38.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tqdm\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "\u001b[K     |████████████████████████████████| 78 kB 18.2 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: tqdm, regex, joblib, click, nltk\n",
      "Successfully installed click-8.1.7 joblib-1.4.2 nltk-3.9.1 regex-2024.11.6 tqdm-4.67.1\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "— Effectuez une normalisation des mots (racine ou radical)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "— Comparez les résultats obtenus entre le stemming et la lemmatisation (La lemmatisation ramène les mots à leur forme canonique en tenant compte du contexte grammatical.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Code de comparaison entre le stemming et la lemmatisation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
